#!/usr/bin/env python
# logappend
# rainy_day_hackers
# Sep 13, 2014
#

# assumptions:
# path to logappend

import argparse
import sys
import os.path
from subprocess import check_output

#parser = argparse.ArgumentParser(description='runs the provided executable and reports on expect results vs. actual')
# parser.add_argument('-r', dest='logr', action='store', help="The path to enemy logread and filename")
# parser.add_argument('-a', dest='loga', action='store', help="The path to enemy logappend and filename")
#parser.add_argument('-g', dest='generic', action='store', help="generic path to enemy directory")

#args, unknown = parser.parse_known_args()

# can we use our own test script?
#if (len(unknown) or not (args.execu and args.batch)):
#        print("rtfm!")
#        print("The Manual: -r path/to/enemylogread -a path/to/enemylogappend")
#        sys.exit(-1)

#if not os.path.isfile(args.logr)
#        print("path to enemy logread is wrong")
#        sys.exit(-1)
#
#if not os.path.isfile(args.loga)
#        print("path to enemy logappend is wrong")
#        sys.exit(-1)


# Overview
#
# a) we first invoke the -b version of the executable on willfail1
# b) then iterate (starting from beginning again) through willfail1 using exec without -b
# c) repeat steps a and b for willfail2
#
# More specifically
#
# However we need to create mini-batch versions so that we can determine simply where something fails. This
# means first parsing the willfail (which separates tests via //comments). We can use these comments as documentation
# for what kind of error we found. So, the lines between //comments will be created into minibatch files, the output
# of each can be more effectively evaluated because it is a limited case and always a unique guest/employee that is
# easily traced back if requried.


count = 0
oldtestline=''
minibatch='minibatch'


willfail=open('willfail10')
for testline in willfail:
    if testline[0] == "/":                              # divider
        count += 1                                      # which test are you on?
        tempresults=open('foo', "w+")
        theirresults=open('foo2', "w+")
        #call(["./logappend", "-b", "minibatch"], stdout=tempresults) # run as batch put results somewhere
        tempresults.write(check_output(["./logappend -b minibatch"], shell=True)) # only good if you really trust the input
        tempresults.seek(0)
        print("debugging, value of tempresults is {0}".format(tempresults.read()))
        if not("invalid" == tempresults.read()):        # invalid should be the only thing in there and only once
                print("correctness violation at test {0} - {1}\n".format(count, oldtestline))
                tempresults.close()

        if count < 22:                                  # first 22 tests are one liners
            if os.path.isfile("log1"):                    # was a log created? teams may handle differently
                #call(["./logread", "-K", "token", "-S", "log1"], stdout=theirresults)     # capture the logread of those results
                theirresults.write(check_output(["./logread -K token -S log1"], shell=True)) #trusted output only
                theirresults.close()
                if os.stat('foo2').st_size > 0:         # if they made a log, it should have no entries and so foo2 == 0 bytes
                    print("correctness violation at test {0} - {1}\n".format(count, oldtestline))
        else:                                           # generate expected output
            # run our own logappend logread to genereate expected output
            # first capture their resultts for posterity
            # call(["./logread", "-K", "token", "-S", "log1"], stdout=theirresults)     # capture the logread of their results
            theirresults.write(check_output(["./logread -K token -S log1"], shell=True))     # capture the logread of their results
            # then run our logappend in batch mode on the minibatch
            call(["./generateDB -b minibatch"], shell=True)
            tempresults2=open('foobar', "w+")
            #call(["./readDB", "-K", "token", "-S", "log1"], stdout=tempresults2)    # run as batch put our results somewhere
            tempresults2.write(check_output(["./readDB -K token -S log1"], shell=True))    # run as batch put our results somewhere
            theirresults.close()
            tempresults2.close()
            result=call(["diff", "foobar", "foo2"])     # take a quick look (this may or may not be the most robust)
            if result:
                print("correctness violation at test {0} - {1}\n".format(count,oldtestline))

        # cleanup and make naming reflect what is broke
        oldtestline = testline
        if os.path.isfile("minibatch"):
            os.remove(minibatch)
        if os.path.isfile("foo"):
            os.remove("foo")
        if os.path.isfile("foo2"):
            os.remove("foo2")
        if os.path.isfile("foobar"):
            os.remove("foobar")

    else:                                                   # make the new minibatch file
        open(minibatch,"a").write(testline)                 # append to mini batch file


