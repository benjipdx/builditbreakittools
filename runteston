#!/usr/bin/env python
# logappend
# rainy_day_hackers
# Sep 13, 2014
#

import argparse
import sys
import os.path
from subprocess import check_output
from subprocess import call
import string


# Overview
#
# invoke the -b version of the executable based on the willfail file
#
# More specifically
#
# Create mini-batch versions so that we can determine simply where something fails. This
# means first parsing the willfail (which separates tests via //comments). We can use these comments as documentation
# for what kind of error we found. So, the lines between //comments will be created into minibatch files, the output
# of each can be more effectively evaluated because it is a limited case and always a unique guest/employee that is
# easily traced back if requried.
#
# Does not handle token alteration or security violations or integrity errors. correctness only.


count = 0
oldtestline=''
minibatch='minibatch'

# clean up from any previous runs
if os.path.isfile(minibatch):
    os.remove(minibatch)
if os.path.isfile('log1'):
    os.remove('log1')
if os.path.isfile('finalresults'):
    os.remove('finalresults')

examinethis=open('finalresults',"a")                    # look here to see how it went


for item in ["willfail10", "willfail20"]:
    print(item)
    testfile=open(item,"r")
    examinethis.write(item)
    for testline in testfile:
        if testline[0] == "/":                              # divider
            call(["./logappend", "-B", "minibatch"])        # run as batch put results somewhere

            if count < 16:                                  # first 22 tests are one liners
                if os.path.isfile("log1"):                  # was a log created? teams may handle differently
                    theirresults = check_output(["./logread -K token -S log1"], shell=True)     # capture the logread of those results
                    if theirresults:                        # if file exists it should be empty
                        examinethis.write("correctness violation at test {0} - {1}\n".format(count, oldtestline))
            else:                                           # generate expected output
                # run our own logappend logread to genereate expected output
                # first capture their results for posterity
                theirresults = str(check_output(["./logread", "-K", "token", "-S", "log1"]))
                # then run our logappend in batch mode on the minibatch
                call(["./generateDB -B minibatch"], shell=True)
                # now read the log we made and capture the logread of our results
                ourresults = str(check_output(["./readDB", "-K", "token", "-S", "log1"]))
                if not (theirresults == ourresults):
                    examinethis.write("correctness violation at test {0} - {1}\n".format(count, oldestline))


            # cleanup and make naming reflect what is broke
            count += 1                                      # which test are you on?
            oldtestline = testline
            if os.path.isfile("minibatch"):
                os.remove(minibatch)
            if os.path.isfile('log1'):
                os.remove('log1')
        else:                                               # make the new minibatch file
            m=open(minibatch,"a")
            m.write(testline)                               # append to mini batch file
            m.close()

    # cleanup
    testfile.close()

examinethis.close()
